{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":507,"status":"ok","timestamp":1707050100501,"user":{"displayName":"Siddhi Patade","userId":"04618896576423067128"},"user_tz":-330},"id":"988fYqJ6A9wN"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from keras.models import Sequential\n","from keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, GRU, Dense, Dropout\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","# Load the dataset\n","url = \"https://raw.githubusercontent.com/mpasco/MalbehavD-V1/main/MalBehavD-V1-dataset.csv\"\n","data = pd.read_csv(url)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1400,"status":"ok","timestamp":1707050104233,"user":{"displayName":"Siddhi Patade","userId":"04618896576423067128"},"user_tz":-330},"id":"bLCn-piUA_Bd"},"outputs":[],"source":["# Assuming 'labels' is the column containing binary labels\n","y = data['labels']\n","\n","# Drop unnecessary columns and extract API call sequences\n","X_sequences = data.drop(['sha256', 'labels'], axis=1).apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n","\n","\n","# Tokenize the API call sequences\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X_sequences)\n","# Convert text to sequences\n","X_padded = pad_sequences(tokenizer.texts_to_sequences(X_sequences), padding='post')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":426,"status":"ok","timestamp":1707050106564,"user":{"displayName":"Siddhi Patade","userId":"04618896576423067128"},"user_tz":-330},"id":"qVnt828HBGGL"},"outputs":[],"source":["# Encode labels\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from keras.models import Sequential\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.optimizers import Adam\n","from keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, GRU, Dense, Dropout\n","import tensorflow as tf\n","from keras.models import load_model\n","\n","# Build the CNN-BiGRU hybrid model\n","\n","embedding_dim = 100\n","cnn_filters = 256  \n","kernel_size = 5\n","bigru_units = 256 \n","dense_units = 512\n","model = Sequential()\n","\n","# Word Embedding Layer\n","model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=X_padded.shape[1]))\n","\n","# Convolutional Layers\n","model.add(Conv1D(filters=cnn_filters, kernel_size=kernel_size, activation='relu', padding='same'))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Conv1D(filters=cnn_filters // 2, kernel_size=kernel_size, activation='relu', padding='same'))\n","model.add(MaxPooling1D(pool_size=2))\n","\n","# Bi-directional GRU Layer\n","model.add(Bidirectional(GRU(bigru_units, dropout=0.5, recurrent_dropout=0.5, return_sequences=True)))\n","model.add(Bidirectional(GRU(bigru_units // 2, dropout=0.5, recurrent_dropout=0.3)))\n","\n","# Additional Dense Layers\n","model.add(Dense(dense_units, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(dense_units // 2, activation='relu'))\n","model.add(Dense(dense_units // 4, activation='relu')) \n","model.add(Dropout(0.3))  \n","\n","# Output Layer\n","model.add(Dense(1, activation='sigmoid'))  # Binary classification\n","\n","# Compile the model with a smaller learning rate\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Early stopping callback\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","# Model checkpoint callback to save the best model during training\n","model_checkpoint = ModelCheckpoint(filepath=\"best_model.h5\", monitor='val_accuracy', save_best_only=True)\n","\n","# Train the model with increased batch size and fewer epochs\n","history = model.fit(X_train, y_train, epochs=6, batch_size=256, validation_data=(X_test, y_test),\n","                    callbacks=[early_stopping, model_checkpoint])\n","\n","# Example of loading the saved model for prediction\n","loaded_model = load_model(\"best_model.h5\")\n","\n","# Evaluate the loaded model\n","loss, accuracy = loaded_model.evaluate(X_test, y_test)\n","print(f\"Test Accuracy (Loaded Model): {accuracy * 100:.2f}%\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPWFIyiGeq7OJzh/EeZX1Vi","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
